<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.313">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Kevin Jablonka">
<meta name="dcterms.date" content="2024-04-24">

<title>Lamalab Tool and Paper Notes - 11&nbsp; Uncertainty-Aware Yield Prediction with Multimodal Molecular Features</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../tools/showyourwork.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<style>
    .quarto-title-block .quarto-title-banner {
      background-image: url(chen_yield_pred_2024_images/dalle_yield.webp);
background-size: cover;
    }
    </style>

  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title"><span class="chapter-title">Uncertainty-Aware Yield Prediction with Multimodal Molecular Features</span></h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title d-none d-lg-block"><span class="chapter-title">Uncertainty-Aware Yield Prediction with Multimodal Molecular Features</span></h1>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Kevin Jablonka </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">April 24, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Lamalab Tool and Paper Notes</a> 
    </div>
      </div>
      <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
      </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Tool and paper minutes</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">Tools</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../tools/hydra.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Hydra</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../tools/ip_rotator.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">IP Rotator</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../tools/polars.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Polars</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../tools/thunder_client.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Thunder Client</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../tools/tmux.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">tmux</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../tools/trimean.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Robust statistics and Trimean</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../tools/pandarallel.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Easy fast <code>.apply</code> for pandas</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../tools/bfg.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">BFG Repo-Cleaner</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../tools/showyourwork.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">showyourwork</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">Papers</a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../papers/chem_yield_prediction_2024.html" class="sidebar-item-text sidebar-link active"><span class="chapter-title">Uncertainty-Aware Yield Prediction with Multimodal Molecular Features</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#why-discussing-this-paper" id="toc-why-discussing-this-paper" class="nav-link active" data-scroll-target="#why-discussing-this-paper">Why discussing this paper?</a></li>
  <li><a href="#context" id="toc-context" class="nav-link" data-scroll-target="#context">Context</a></li>
  <li><a href="#prior-work" id="toc-prior-work" class="nav-link" data-scroll-target="#prior-work">Prior work</a>
  <ul class="collapse">
  <li><a href="#ahneman-et-al.-2018" id="toc-ahneman-et-al.-2018" class="nav-link" data-scroll-target="#ahneman-et-al.-2018">Ahneman et al.&nbsp;(2018)</a></li>
  <li><a href="#schwaller-et-al.-2020-2021" id="toc-schwaller-et-al.-2020-2021" class="nav-link" data-scroll-target="#schwaller-et-al.-2020-2021">Schwaller et al.&nbsp;(2020, 2021)</a></li>
  <li><a href="#kwon-et-al.-2022" id="toc-kwon-et-al.-2022" class="nav-link" data-scroll-target="#kwon-et-al.-2022">Kwon et al.&nbsp;(2022)</a></li>
  </ul></li>
  <li><a href="#problem-setting" id="toc-problem-setting" class="nav-link" data-scroll-target="#problem-setting">Problem setting</a></li>
  <li><a href="#approach" id="toc-approach" class="nav-link" data-scroll-target="#approach">Approach</a>
  <ul class="collapse">
  <li><a href="#graph-encoder-and-smiles-encoder" id="toc-graph-encoder-and-smiles-encoder" class="nav-link" data-scroll-target="#graph-encoder-and-smiles-encoder">Graph encoder and SMILES encoder</a></li>
  <li><a href="#human-features-encoder" id="toc-human-features-encoder" class="nav-link" data-scroll-target="#human-features-encoder">Human-features encoder</a></li>
  <li><a href="#fusion" id="toc-fusion" class="nav-link" data-scroll-target="#fusion">Fusion</a></li>
  <li><a href="#uncertainty-quantification" id="toc-uncertainty-quantification" class="nav-link" data-scroll-target="#uncertainty-quantification">Uncertainty (quantification)</a></li>
  </ul></li>
  <li><a href="#results" id="toc-results" class="nav-link" data-scroll-target="#results">Results</a>
  <ul class="collapse">
  <li><a href="#ablations" id="toc-ablations" class="nav-link" data-scroll-target="#ablations">Ablations</a></li>
  </ul></li>
  <li><a href="#take-aways" id="toc-take-aways" class="nav-link" data-scroll-target="#take-aways">Take aways</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="why-discussing-this-paper" class="level2">
<h2 class="anchored" data-anchor-id="why-discussing-this-paper">Why discussing this paper?</h2>
<p>I chose Chen et al.’s paper<span class="citation" data-cites="Chen_2024"><sup><a href="chem_yield_prediction_2024.html#ref-Chen_2024" role="doc-biblioref">1</a></sup></span> for our journal club because</p>
<ul>
<li>An important and interesting problem in chemistry</li>
<li>Uses many of the techniques we care about in our group</li>
</ul>
</section>
<section id="context" class="level2">
<h2 class="anchored" data-anchor-id="context">Context</h2>
<p>Predicting the yield of chemical reactions is a crucial task in organic chemistry. It can help to optimize the synthesis of new molecules, reduce the number of experiments needed, and save time and resources. However, predicting the yield of a reaction is challenging due to the complexity of chemical reactions and the large number of factors that can influence the outcome.</p>
</section>
<section id="prior-work" class="level2">
<h2 class="anchored" data-anchor-id="prior-work">Prior work</h2>
<section id="ahneman-et-al.-2018" class="level3">
<h3 class="anchored" data-anchor-id="ahneman-et-al.-2018">Ahneman et al.&nbsp;(2018)</h3>
<p>Ahneman et al.<span class="citation" data-cites="Ahneman_2018"><sup><a href="chem_yield_prediction_2024.html#ref-Ahneman_2018" role="doc-biblioref">2</a></sup></span> reported in <em>Science</em> a random forest model that predicts the yield of chemical reactions in a high-throughput dataset (palladium-catalyzed Buchwald-Hartwig cross-coupling reactions). For this, the authors created a set of features using computational techniques.</p>
<p>A very interesting aspect of this work is the subsequent exchange with Chuang and Keiser<span class="citation" data-cites="Chuang_2018"><sup><a href="chem_yield_prediction_2024.html#ref-Chuang_2018" role="doc-biblioref">3</a></sup></span> who point out that the chemical features used in the work by Ahneman et al.&nbsp;perform not distinguishably better than non-meaningful features.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="chen_yield_pred_2024_images/362_aat8603_f1.jpeg" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure taken from Chuang and Keiser’s paper<span class="citation" data-cites="Chuang_2018"><sup><a href="chem_yield_prediction_2024.html#ref-Chuang_2018" role="doc-biblioref">3</a></sup></span> illustrating models trained with various featurization approaches.</figcaption><p></p>
</figure>
</div>
</section>
<section id="schwaller-et-al.-2020-2021" class="level3">
<h3 class="anchored" data-anchor-id="schwaller-et-al.-2020-2021">Schwaller et al.&nbsp;(2020, 2021)</h3>
<p>Schwaller et al.<span class="citation" data-cites="schwaller2020data schwaller2021prediction"><sup><a href="chem_yield_prediction_2024.html#ref-schwaller2020data" role="doc-biblioref">4</a>,<a href="chem_yield_prediction_2024.html#ref-schwaller2021prediction" role="doc-biblioref">5</a></sup></span> utilized BERT models with a regression head to predict yields based on reaction SMILES.</p>
<p>They observed multiple interesting effects:</p>
<ul>
<li>The performance on high-throughput datasets is good, on USPTO datasets the models are not predictive (<span class="math inline">\(R^2\)</span> on a random split of 0.117 for the gram scale)</li>
<li>The yield distribution depends on the scale, which might be due to reaction at larger scale being better optimized</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="chen_yield_pred_2024_images/yield_scales.jpg" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Figure taken from Schwaller et al.<span class="citation" data-cites="schwaller2021prediction"><sup><a href="chem_yield_prediction_2024.html#ref-schwaller2021prediction" role="doc-biblioref">5</a></sup></span> illustrating the distribution of yields on different scales.</figcaption><p></p>
</figure>
</div>
</section>
<section id="kwon-et-al.-2022" class="level3">
<h3 class="anchored" data-anchor-id="kwon-et-al.-2022">Kwon et al.&nbsp;(2022)</h3>
<p>Kwon et al.<span class="citation" data-cites="Kwon_2022"><sup><a href="chem_yield_prediction_2024.html#ref-Kwon_2022" role="doc-biblioref">6</a></sup></span>, in contrast, used graph neural networks to predict yields. They pass reactants and products through a graph neural network and concatenate the embeddings to predict the yield. They train on a similar loss as the work at hand (but use also use dropout Monte-Carlo<span class="citation" data-cites="gal2016dropout"><sup><a href="chem_yield_prediction_2024.html#ref-gal2016dropout" role="doc-biblioref">7</a></sup></span> to estimate the epistemic uncertainty).</p>
</section>
</section>
<section id="problem-setting" class="level2">
<h2 class="anchored" data-anchor-id="problem-setting">Problem setting</h2>
<ul>
<li>prior works perform well on high-throughput datasets but not on real-world datasets</li>
<li>this is partially due to a lot of noise in datasets</li>
<li>of course, reaction conditions are important, too</li>
</ul>
<p>Additionally, the authors propose that the previous representations might not be “rich” enough to capture the complexity of chemical reactions.</p>
</section>
<section id="approach" class="level2">
<h2 class="anchored" data-anchor-id="approach">Approach</h2>
<p>The authors propose to fuse multiple features. In addition, they also use a special loss function and a mixture of experts (MoE) model used to transform human-designed features.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="chen_yield_pred_2024_images/approach.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">Overview of the model architecture. Figure taken from Chem et al.<span class="citation" data-cites="Chen_2024"><sup><a href="chem_yield_prediction_2024.html#ref-Chen_2024" role="doc-biblioref">1</a></sup></span></figcaption><p></p>
</figure>
</div>
<section id="graph-encoder-and-smiles-encoder" class="level3">
<h3 class="anchored" data-anchor-id="graph-encoder-and-smiles-encoder">Graph encoder and SMILES encoder</h3>
<p>The authors pretrain the graph and SMILES encoders using a contrastive loss. The graph encoder is a GNN, the SMILES encoder is a transformer.</p>
<section id="graph-convolutional-neural-network" class="level4">
<h4 class="anchored" data-anchor-id="graph-convolutional-neural-network">Graph convolutional neural network</h4>
<p>Their graph encoder is basically a message graph convolutional neural network. The authors use the <code>DGL</code> library to <a href="https://github.com/jychen229/reaction-yield-prediction/blob/main/model.py#L237">implement this</a>.</p>
<p>The forward pass looks like this:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _ <span class="kw">in</span> <span class="bu">range</span>(<span class="va">self</span>.num_step_message_passing):</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>    node_feats <span class="op">=</span> <span class="va">self</span>.activation(<span class="va">self</span>.gnn_layer(g, node_feats, edge_feats)).unsqueeze(<span class="dv">0</span>)</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>    node_feats, hidden_feats <span class="op">=</span> <span class="va">self</span>.gru(node_feats, hidden_feats)</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    node_feats <span class="op">=</span> node_feats.squeeze(<span class="dv">0</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Where the GNN layer performs a simple operation such as</p>
<p><span class="math display">\[
\mathbf{x}_i^{\prime}=\boldsymbol{\Theta}^{\top} \sum_{j \in \mathcal{N}(i) \cup\{i\}} \frac{e_{j, i}}{\sqrt{\hat{d}_j \hat{d}_i}} \mathbf{x}_j
\]</span></p>
<p>where <span class="math inline">\(\hat{d}_i\)</span> is the degree of node <span class="math inline">\(i\)</span> and <span class="math inline">\(\boldsymbol{\Theta}\)</span> is a learnable weight matrix. <span class="math inline">\(\mathcal{N}(i)\)</span> is the set of neighbors of node <span class="math inline">\(i\)</span>. <span class="math inline">\(\mathbf{x}_i\)</span> is the node embedding of node <span class="math inline">\(i\)</span>, <span class="math inline">\(e_{j, i}\)</span> is the edge feature between node <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span>.</p>
<p>The node embeddings are then aggregated using Set2Set pooling<span class="citation" data-cites="vinyals2016order"><sup><a href="chem_yield_prediction_2024.html#ref-vinyals2016order" role="doc-biblioref">8</a></sup></span>.</p>
</section>
<section id="smiles-encoder" class="level4">
<h4 class="anchored" data-anchor-id="smiles-encoder">SMILES encoder</h4>
<p>For encoding SMILES, the use a transformer model. <a href="https://github.com/jychen229/reaction-yield-prediction/blob/main/model.py#L237">In their code</a>, they seem to pass through only one transformer layer.</p>
<p>The forward pass looks like this:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> <span class="va">self</span>.token_embedding(text)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> x <span class="op">+</span> <span class="va">self</span>.positional_embedding</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> x.permute(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">2</span>)  <span class="co"># NLD -&gt; LND</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> <span class="va">self</span>.transformer(x)</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> x.permute(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">2</span>)  <span class="co"># LND -&gt; NLD</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> <span class="va">self</span>.ln_final(x)</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a>x <span class="op">=</span> <span class="va">self</span>.pooler(x[:,<span class="dv">0</span>,:])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>They take the first token of the sequence and pass it through a linear layer to get the final representation.</p>
</section>
<section id="contrastive-training" class="level4">
<h4 class="anchored" data-anchor-id="contrastive-training">Contrastive training</h4>
<p>The authors use a contrastive loss to train the encoders.</p>
<p><span class="math display">\[
\mathcal{L}_c=-\frac{1}{2} \log \frac{e^{\left\langle f_G^j, f_S^j\right\rangle / \tau}}{\sum_{k=1}^N e^{\left\langle f_G^j, f_S^k\right\rangle / \tau}}-\frac{1}{2} \log \frac{e^{\left\langle f_G^j, f_S^j\right\rangle / \tau}}{\sum_{k=1}^N e^{\left\langle f_G^k, f_S^j\right\rangle / \tau}},
\]</span></p>
<p>In contrastive training, we try to maximize the similarity between positive pairs and minimize the similarity between negative pairs. In the equation above, <span class="math inline">\(f_G^j\)</span> and <span class="math inline">\(f_S^j\)</span> are the representations of the graph and SMILES of the same reaction, respectively. <span class="math inline">\(\tau\)</span> is a temperature parameter.</p>
<p>Such contrastive training allows to pretrain the encoders on a large dataset without labels.</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>Contrastive learning is one of the most popular methods in self-supervised learning. A good overview can be found in <a href="https://lilianweng.github.io/posts/2021-05-31-contrastive/">Lilian Weng’s amazing blog</a>.</p>
</div>
</div>
</section>
</section>
<section id="human-features-encoder" class="level3">
<h3 class="anchored" data-anchor-id="human-features-encoder">Human-features encoder</h3>
<p>The authors also encode additional features with feedforward networks in a mixture of experts (MoE) model. The key idea behind MoE is that we replace “conventional layers” with “MoE layers” which are copies of the same layer. A gating network decides, based on the input, which layer to use. This is powerful if we sparsely select the experts-then only a subset of all weights are used in a given forward pass.</p>
<p><span class="math display">\[
\operatorname{MoE}\left(x_H\right)=\sum_{i=1}^t \mathcal{G}\left(x_H\right)_i \cdot E_i\left(x_H\right)
\]</span></p>
<p>This is a mixture of experts model. The authors use a gating network <span class="math inline">\(\mathcal{G}\)</span> to decide which expert to use. The experts <span class="math inline">\(E_i\)</span> are simple feedforward networks. The gating network might be a simple softmax layer:</p>
<p><span class="math display">\[
G_\sigma(x)=\operatorname{Softmax}\left(x \cdot W_g\right)
\]</span></p>
<p>in practice, one can improve that by adding sparsity (e.g.&nbsp;selecting top-k).</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>MoE<span class="citation" data-cites="shazeer2017outrageously"><sup><a href="chem_yield_prediction_2024.html#ref-shazeer2017outrageously" role="doc-biblioref">9</a></sup></span> has become popular recently as a way to scale LLMs. You might have across model names like Mixtral-8x7B<span class="citation" data-cites="jiang2024mixtral"><sup><a href="chem_yield_prediction_2024.html#ref-jiang2024mixtral" role="doc-biblioref">10</a></sup></span>, which indicates that the model is a mixture of 8 experts, each of which is a 7B parameter model. The total number of parameters is 47B parameters, but the inference cost is similar to the one of a 14B parameter model. (Note however, that memory consumption is still high as all experts need to be loaded into memory.)</p>
<p><a href="https://cameronrwolfe.substack.com/p/conditional-computation-the-birth">This blog by Cameron Wolfe</a> gives a good overview. You might also find <a href="https://www.youtube.com/watch?v=mwO6v4BlgZQ">Yannic Kilcher’s video about Mixtral of Experts</a> useful.</p>
</div>
</div>
</section>
<section id="fusion" class="level3">
<h3 class="anchored" data-anchor-id="fusion">Fusion</h3>
<p>The fusion of the different features is done by concatenating them</p>
<p>The complete forward pass looks like this:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>r_graph_feats <span class="op">=</span> torch.<span class="bu">sum</span>(torch.stack([<span class="va">self</span>.clme.mpnn(mol) <span class="cf">for</span> mol <span class="kw">in</span> rmols]), <span class="dv">0</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>p_graph_feats <span class="op">=</span> <span class="va">self</span>.clme.mpnn(pmols)</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>feats, a_loss <span class="op">=</span> <span class="va">self</span>.mlp(input_feats)</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>seq_feats <span class="op">=</span> <span class="va">self</span>.clme.transformer(smiles)</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>concat_feats <span class="op">=</span> torch.cat([r_graph_feats, p_graph_feats, feats, seq_feats], <span class="dv">1</span>)</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>out <span class="op">=</span> <span class="va">self</span>.predict(concat_feats)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>where the <code>mpnn</code> method is the graph encoder, the <code>transformer</code> method is the SMILES encoder, and the <code>mlp</code> method is the human-features encoder.</p>
</section>
<section id="uncertainty-quantification" class="level3">
<h3 class="anchored" data-anchor-id="uncertainty-quantification">Uncertainty (quantification)</h3>
<p>The authors define the prediction as</p>
<p><span class="math display">\[
\hat{y}=\mu(\boldsymbol{x})+\epsilon * \sigma(\boldsymbol{x})
\]</span></p>
<p>where <span class="math inline">\(\mu(\boldsymbol{x})\)</span> is the prediction, <span class="math inline">\(\sigma(\boldsymbol{x})\)</span> is the uncertainty, and <span class="math inline">\(\epsilon\)</span> is a random variable sampled from a normal distribution.</p>
<p>The model is trained with a loss function that includes the uncertainty:</p>
<p><span class="math display">\[
\mathcal{L}_u=\frac{1}{N} \sum_{i=1}^N\left[\frac{1}{\sigma\left(\boldsymbol{x}_i\right)^2}\left\|y_i-\mu\left(\boldsymbol{x}_i\right)\right\|^2+\log \sigma\left(\boldsymbol{x}_i\right)^2\right]
\]</span></p>
<p>The <span class="math inline">\(\sigma\)</span> term is capturing observation noise (aleatoric uncertainty).</p>
<div class="callout-note callout callout-style-default callout-captioned">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-caption-container flex-fill">
Note
</div>
</div>
<div class="callout-body-container callout-body">
<p>This loss comes from the idea of variational inference.</p>
<p><span class="math display">\[
\mathcal{L}(\boldsymbol{\lambda})=-\mathbb{E}_{q(\boldsymbol{\theta} ; \boldsymbol{\lambda})}[\log p(\mathbf{y} \mid \mathbf{x}, \boldsymbol{\theta})]+\mathrm{KL}(q(\boldsymbol{\theta} ; \boldsymbol{\lambda}) \| p(\boldsymbol{\theta}))
\]</span></p>
<p>In this equation, the first term is the negative log-likelihood, and the second term is the KL divergence between the approximate posterior <span class="math inline">\(q(\boldsymbol{\theta} ; \boldsymbol{\lambda})\)</span> and the prior <span class="math inline">\(p(\boldsymbol{\theta})\)</span>. The KL divergence is a measure of how much the approximate posterior diverges from the prior. The idea is to minimize the negative log-likelihood while keeping the approximate posterior close to the prior. This is a way to quantify the uncertainty in the model.</p>
<p>The idea comes from Bayesian inference, where we want to estimate the posterior distribution over the parameters of the model. In practice, this is intractable, so we use variational inference to approximate the posterior with a simpler distribution. The posterior (which quantifies uncertainty) is typically computationally expensive to compute, so we use variational inference to approximate it with a simpler distribution, this is called variational inference. Since during training, we do some sampling, we need to perform a reparametrization trick<span class="citation" data-cites="kingma2015variational"><sup><a href="chem_yield_prediction_2024.html#ref-kingma2015variational" role="doc-biblioref">11</a></sup></span> to make the gradients flow through the sampling operation.</p>
</div>
</div>
</section>
</section>
<section id="results" class="level2">
<h2 class="anchored" data-anchor-id="results">Results</h2>
<p>As in most ML papers, we have tables with bold numbers, e.g.&nbsp;for a dataset with amide coupling reactions:</p>
<table class="table">
<colgroup>
<col style="width: 6%">
<col style="width: 30%">
<col style="width: 30%">
<col style="width: 32%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Model</th>
<th style="text-align: center;">MAE <span class="math inline">\(\downarrow\)</span></th>
<th style="text-align: center;">RMSE <span class="math inline">\(\downarrow\)</span></th>
<th style="text-align: center;"><span class="math inline">\(R^2 \uparrow\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Mordred</td>
<td style="text-align: center;"><span class="math inline">\(15.99 \pm 0.14\)</span></td>
<td style="text-align: center;"><span class="math inline">\(21.08 \pm 0.16\)</span></td>
<td style="text-align: center;"><span class="math inline">\(0.168 \pm 0.010\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">YieldBert</td>
<td style="text-align: center;"><span class="math inline">\(16.52 \pm 0.20\)</span></td>
<td style="text-align: center;"><span class="math inline">\(21.12 \pm 0.13\)</span></td>
<td style="text-align: center;"><span class="math inline">\(0.172 \pm 0.016\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">YieldGNN</td>
<td style="text-align: center;"><span class="math inline">\(\underline{15.27 \pm 0.18}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\underline{19.82} \pm 0.08\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\underline{0.216} \pm 0.013\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">MPNN</td>
<td style="text-align: center;"><span class="math inline">\(16.31 \pm 0.22\)</span></td>
<td style="text-align: center;"><span class="math inline">\(20.86 \pm 0.27\)</span></td>
<td style="text-align: center;"><span class="math inline">\(0.188 \pm 0.021\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">Ours</td>
<td style="text-align: center;"><span class="math inline">\(\mathbf{1 4 . 7 6} \pm \mathbf{0 . 1 5}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\mathbf{1 9 . 3 3} \pm \mathbf{0 . 1 0}\)</span></td>
<td style="text-align: center;"><span class="math inline">\(\mathbf{0 . 2 6 2} \pm \mathbf{0 . 0 0 9}\)</span></td>
</tr>
</tbody>
</table>
<p>Here, their model outperforms the baselines. But it is also interesting to see how well the Mordred baseline performs compared to much more complex models.</p>
<p>The pattern of their model being bold in tables is persistent across datasets.</p>
<section id="ablations" class="level3">
<h3 class="anchored" data-anchor-id="ablations">Ablations</h3>
<p>The authors perform ablations to understand the importance of the different components of their model. While there are some differences, the differences are not drastic (partially overlapping errorbars).</p>
<table class="table">
<colgroup>
<col style="width: 21%">
<col style="width: 26%">
<col style="width: 26%">
<col style="width: 26%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Model</th>
<th style="text-align: center;">MAE <span class="math inline">\(\downarrow\)</span></th>
<th style="text-align: center;">RMSE <span class="math inline">\(\downarrow\)</span></th>
<th style="text-align: center;"><span class="math inline">\(R^2 \uparrow\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">Ours</td>
<td style="text-align: center;"><span class="math inline">\(14.76 \pm 0.15\)</span></td>
<td style="text-align: center;"><span class="math inline">\(19.33 \pm 0.10\)</span></td>
<td style="text-align: center;"><span class="math inline">\(0.262 \pm 0.009\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">w/o UQ</td>
<td style="text-align: center;"><span class="math inline">\(15.08 \pm 0.13\)</span></td>
<td style="text-align: center;"><span class="math inline">\(19.63 \pm 0.09\)</span></td>
<td style="text-align: center;"><span class="math inline">\(0.249 \pm 0.009\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">w/o <span class="math inline">\(\mathcal{L}_r\)</span></td>
<td style="text-align: center;"><span class="math inline">\(14.80 \pm 0.16\)</span></td>
<td style="text-align: center;"><span class="math inline">\(19.51 \pm 0.10\)</span></td>
<td style="text-align: center;"><span class="math inline">\(0.261 \pm 0.010\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">w/o MoE</td>
<td style="text-align: center;"><span class="math inline">\(15.12 \pm 0.18\)</span></td>
<td style="text-align: center;"><span class="math inline">\(20.03 \pm 0.13\)</span></td>
<td style="text-align: center;"><span class="math inline">\(0.230 \pm 0.012\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">w/o Seq.</td>
<td style="text-align: center;"><span class="math inline">\(14.97 \pm 0.16\)</span></td>
<td style="text-align: center;"><span class="math inline">\(19.55 \pm 0.11\)</span></td>
<td style="text-align: center;"><span class="math inline">\(0.261 \pm 0.010\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;">w/o Graph</td>
<td style="text-align: center;"><span class="math inline">\(15.06 \pm 0.15\)</span></td>
<td style="text-align: center;"><span class="math inline">\(19.59 \pm 0.10\)</span></td>
<td style="text-align: center;"><span class="math inline">\(0.260 \pm 0.009\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;">w/o H.</td>
<td style="text-align: center;"><span class="math inline">\(15.83 \pm 0.20\)</span></td>
<td style="text-align: center;"><span class="math inline">\(20.46 \pm 0.18\)</span></td>
<td style="text-align: center;"><span class="math inline">\(0.212 \pm 0.016\)</span></td>
</tr>
</tbody>
</table>
</section>
</section>
<section id="take-aways" class="level2">
<h2 class="anchored" data-anchor-id="take-aways">Take aways</h2>
<ul>
<li>A lot of machinery, but not a drastic improvement</li>
<li>It is the data, stupid! 😉 (It is not really clear how this is even supposed to work with information about the conditions)</li>
<li>Interestingly, they didn’t test USPTO or other datasets</li>
<li>Their approach with frozen encoders is interesting, it would have been interesting to see learning curves to better understand the data efficiency of the approach</li>
</ul>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>
<div id="refs" class="references csl-bib-body" data-line-spacing="2" role="doc-bibliography">
<div id="ref-Ahneman_2018" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">1. </div><div class="csl-right-inline">Ahneman, D. T., Estrada, J. G., Lin, S.,
Dreher, S. D. &amp; Doyle, A. G. <a href="https://doi.org/10.1126/science.aar5169">Predicting reaction
performance in c–n cross-coupling using machine learning</a>.
<em>Science</em> <strong>360</strong>, 186–190 (2018).</div>
</div>
<div id="ref-Chuang_2018" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">2. </div><div class="csl-right-inline">Chuang, K. V. &amp; Keiser, M. J. <a href="https://doi.org/10.1126/science.aat8603">Comment on
<span>‘predicting reaction performance in c–n cross-coupling using
machine learning’</span></a>. <em>Science</em> <strong>362</strong>,
(2018).</div>
</div>
<div id="ref-vinyals2016order" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">3. </div><div class="csl-right-inline">Vinyals, O., Bengio, S. &amp; Kudlur, M. <a href="https://arxiv.org/abs/1511.06391">Order matters: Sequence to
sequence for sets</a>. (2016).</div>
</div>
<div id="ref-shazeer2017outrageously" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">4. </div><div class="csl-right-inline">Shazeer, N. <em>et al.</em> <a href="https://arxiv.org/abs/1701.06538">Outrageously large neural
networks: The sparsely-gated mixture-of-experts layer</a>. (2017).</div>
</div>
<div id="ref-jiang2024mixtral" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">5. </div><div class="csl-right-inline">Jiang, A. Q. <em>et al.</em> <a href="https://arxiv.org/abs/2401.04088">Mixtral of experts</a>.
(2024).</div>
</div>
<div id="ref-kingma2015variational" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">6. </div><div class="csl-right-inline">Kingma, D. P., Salimans, T. &amp; Welling, M.
<a href="https://arxiv.org/abs/1506.02557">Variational dropout and the
local reparameterization trick</a>. (2015).</div>
</div>
<div id="ref-Chen_2024" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">7. </div><div class="csl-right-inline">Chen, J., Guo, K., Liu, Z., Isayev, O. &amp;
Zhang, X. <a href="https://doi.org/10.1609/aaai.v38i8.28668">Uncertainty-aware yield
prediction with multimodal molecular features</a>. <em>Proceedings of
the AAAI Conference on Artificial Intelligence</em> <strong>38</strong>,
8274–8282 (2024).</div>
</div>
<div id="ref-schwaller2020data" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">8. </div><div class="csl-right-inline">Schwaller, P., Vaucher, A. C., Laino, T. &amp;
Reymond, J.-L. Data augmentation strategies to improve reaction yield
predictions and estimate uncertainty. <em>Chemrxiv preprint</em>
(2020).</div>
</div>
<div id="ref-schwaller2021prediction" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">9. </div><div class="csl-right-inline">Schwaller, P., Vaucher, A. C., Laino, T. &amp;
Reymond, J.-L. Prediction of chemical reaction yields using deep
learning. <em>Machine learning: science and technology</em>
<strong>2</strong>, 015016 (2021).</div>
</div>
<div id="ref-Kwon_2022" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">10. </div><div class="csl-right-inline">Kwon, Y., Lee, D., Choi, Y.-S. &amp; Kang, S.
<a href="https://doi.org/10.1186/s13321-021-00579-z">Uncertainty-aware
prediction of chemical reaction yields with graph neural networks</a>.
<em>Journal of Cheminformatics</em> <strong>14</strong>, (2022).</div>
</div>
<div id="ref-gal2016dropout" class="csl-entry" role="doc-biblioentry">
<div class="csl-left-margin">11. </div><div class="csl-right-inline">Gal, Y. &amp; Ghahramani, Z. Dropout as a
bayesian approximation: Representing model uncertainty in deep learning.
in <em>International conference on machine learning</em> 1050–1059
(PMLR, 2016).</div>
</div>
</div>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../tools/showyourwork.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-title">showyourwork</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
  </div>
</nav>
</div> <!-- /content -->



</body></html>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.4.554">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Martiño Ríos-García">
<meta name="dcterms.date" content="2024-05-14">

<title>Lamalab Tool and Paper Notes - Structured information extraction from scientific text with large language models</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../papers/MolCLR_2024.html" rel="next">
<link href="../papers/chem_yield_prediction_2024.html" rel="prev">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>

      .quarto-title-block .quarto-title-banner {
        background-image: url(dagdelen_data_extraction_2024_images/ai_banner.webp);
background-size: cover;
      }
</style>


</head>

<body class="nav-sidebar floating slimcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../papers/llm4mat.html">Papers</a></li><li class="breadcrumb-item"><a href="../papers/dagdelen_data_extraction.html"><span class="chapter-title">Structured information extraction from scientific text with large language models</span></a></li></ol></nav>
        <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="../papers/llm4mat.html">Papers</a></li><li class="breadcrumb-item"><a href="../papers/dagdelen_data_extraction.html"><span class="chapter-title">Structured information extraction from scientific text with large language models</span></a></li></ol></nav>
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title"><span class="chapter-title">Structured information extraction from scientific text with large language models</span></h1>
                      </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Martiño Ríos-García </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">May 14, 2024</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="../">Lamalab Tool and Paper Notes</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../index.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Tool and paper minutes</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Tools</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../tools/hydra.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Hydra</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../tools/ip_rotator.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">IP Rotator</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../tools/polars.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Polars</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../tools/thunder_client.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Thunder Client</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../tools/tmux.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">tmux</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../tools/trimean.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Robust statistics and Trimean</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../tools/pandarallel.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Easy fast <code>.apply</code> for pandas</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../tools/bfg.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">BFG Repo-Cleaner</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../tools/showyourwork.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">showyourwork</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true">
 <span class="menu-text">Papers</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../papers/llm4mat.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Leveraging language representation for materials exploration and discovery</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../papers/chem_yield_prediction_2024.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Uncertainty-Aware Yield Prediction with Multimodal Molecular Features</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../papers/dagdelen_data_extraction.html" class="sidebar-item-text sidebar-link active"><span class="chapter-title">Structured information extraction from scientific text with large language models</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../papers/MolCLR_2024.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Molecular contrastive learning of representations (MolCLR) via graph neural networks</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../papers/PaCh.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">PaCh (Packed Chemicals): Computationally Effective Binary Format for Chemical Structure Encoding</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../papers/ms_prediction_graph_transformers/tandem_ms_prediction_graph_transformers.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Tandem mass spectrum prediction for small molecules using graph transformers</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="../papers/open-source-cheminformatics.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">Open-Source Software Development in Cheminformatics: A Qualitative Analysis of Rationales</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#why-discussing-this-paper" id="toc-why-discussing-this-paper" class="nav-link active" data-scroll-target="#why-discussing-this-paper">Why discussing this paper?</a></li>
  <li><a href="#context" id="toc-context" class="nav-link" data-scroll-target="#context">Context</a></li>
  <li><a href="#prior-work" id="toc-prior-work" class="nav-link" data-scroll-target="#prior-work">Prior work</a>
  <ul class="collapse">
  <li><a href="#old-ages" id="toc-old-ages" class="nav-link" data-scroll-target="#old-ages">Old ages</a></li>
  <li><a href="#chemdataextractor-1.0-and-2.0" id="toc-chemdataextractor-1.0-and-2.0" class="nav-link" data-scroll-target="#chemdataextractor-1.0-and-2.0">ChemDataExtractor 1.0 and 2.0</a></li>
  <li><a href="#trewartha-et-al.-2022" id="toc-trewartha-et-al.-2022" class="nav-link" data-scroll-target="#trewartha-et-al.-2022">Trewartha et al.&nbsp;(2022)</a></li>
  </ul></li>
  <li><a href="#problem-setting" id="toc-problem-setting" class="nav-link" data-scroll-target="#problem-setting">Problem setting</a></li>
  <li><a href="#approach" id="toc-approach" class="nav-link" data-scroll-target="#approach">Approach</a></li>
  <li><a href="#results" id="toc-results" class="nav-link" data-scroll-target="#results">Results</a>
  <ul class="collapse">
  <li><a href="#human-in-the-loop" id="toc-human-in-the-loop" class="nav-link" data-scroll-target="#human-in-the-loop">Human-in-the-loop</a></li>
  </ul></li>
  <li><a href="#take-aways" id="toc-take-aways" class="nav-link" data-scroll-target="#take-aways">Take aways</a></li>
  <li><a href="#references" id="toc-references" class="nav-link" data-scroll-target="#references">References</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block page-columns page-full" id="quarto-document-content">





<section id="why-discussing-this-paper" class="level2">
<h2 class="anchored" data-anchor-id="why-discussing-this-paper">Why discussing this paper?</h2>
<p>I chose Dagdelen et al.’s paper <span class="citation" data-cites="dagdelen_structured_2024">(<a href="#ref-dagdelen_structured_2024" role="doc-biblioref">Dagdelen et al. 2024</a>)</span> for our journal club because:</p>
<ul>
<li>It is one of the last published papers to fine-tune a model for the data extraction task for materials science.</li>
<li>It presents a very robust fine-tuning and evaluation process.</li>
<li>Furthermore, they show how the current models can help with a tedious task such as it is annotating data.</li>
</ul>
</section>
<section id="context" class="level2">
<h2 class="anchored" data-anchor-id="context">Context</h2>
<p>Extracting the unstructured scientific information from the articles that contain it can be a really arduos and time-consuming task. In the recent years, several works have shown the great potential that LLMs have to greatly accelerate this task. However, for some research fields or harder extraction schemas, the general pre-training of these models might not be enough to archieve the desired results. For such cases, fine-tuning have shown to be the adequate technique.</p>
</section>
<section id="prior-work" class="level2">
<h2 class="anchored" data-anchor-id="prior-work">Prior work</h2>
<section id="old-ages" class="level3">
<h3 class="anchored" data-anchor-id="old-ages">Old ages</h3>
<p>Several works from the Ceder group showed the complete tedious process. First, Huo et al. <span class="citation" data-cites="Huo2019">(<a href="#ref-Huo2019" role="doc-biblioref">Huo et al. 2019</a>)</span> use LDA + RF to classify text. To train the RF model they had to manually label 6000 materials paragraphs as they contain synthesis information or not.</p>
<p>In a following work, Kononova et al. <span class="citation" data-cites="Kononova2019">(<a href="#ref-Kononova2019" role="doc-biblioref">Kononova et al. 2019</a>)</span> trained a Word2Vec model, to then feed the embeddings to a BiLSTM-CRF. To train this NN they manually annotated more than 800 paragraphs word-by-word with tags about solid-state synthesis role (material, target, precursor or other). Furthermore, to classify the synthesis operations (NOT OPERATION, MIXING, HEATING, etc) they trained another NN with more annotated data. To this step they also had to <strong>LEMMATIZED</strong> the sentences and obtain each token’s <strong>POS</strong>. Amazing hard work!</p>
<p>Similar works by Kim et al. <span class="citation" data-cites="Kim2017 mysore2019materials Kim2020">(<a href="#ref-Kim2017" role="doc-biblioref">Kim et al. 2017</a>, <a href="#ref-Kim2020" role="doc-biblioref">2020</a>; <a href="#ref-mysore2019materials" role="doc-biblioref">Mysore et al. 2019</a>)</span> in which they applied similar techniques such as word embeddings from language models, then fed to a named entity recognition model.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="dagdelen_data_extraction_2024_images/annotation.png" class="img-fluid figure-img"></p>
<figcaption>Figure taken from Mysore et al.&nbsp;paper <span class="citation" data-cites="mysore2019materials">(<a href="#ref-mysore2019materials" role="doc-biblioref">Mysore et al. 2019</a>)</span> illustrating how they labeled the data for the NER task.</figcaption>
</figure>
</div>
</section>
<section id="chemdataextractor-1.0-and-2.0" class="level3">
<h3 class="anchored" data-anchor-id="chemdataextractor-1.0-and-2.0">ChemDataExtractor 1.0 and 2.0</h3>
<p>Cole et al. <span class="citation" data-cites="Swain2016 Mavrai2021">(<a href="#ref-Swain2016" role="doc-biblioref">Swain and Cole 2016</a>; <a href="#ref-Mavrai2021" role="doc-biblioref">Mavračić et al. 2021</a>)</span> developed ChemDataExtractor which is build from the combination of traditional ML techniques for each NLP task such as lemmatazion, tokenization, POS tagging, it even include Table Parsing. All of these models trained in chemical text, which made this tool a really good option for extracting chemical data from text.</p>
</section>
<section id="trewartha-et-al.-2022" class="level3">
<h3 class="anchored" data-anchor-id="trewartha-et-al.-2022">Trewartha et al.&nbsp;(2022)</h3>
<p>Trewartha el al. <span class="citation" data-cites="Trewartha2022">(<a href="#ref-Trewartha2022" role="doc-biblioref">Trewartha et al. 2022</a>)</span> compared the performance of a simpler model such as a BiLSTM RNN with three more complex transformer models, BERT, SciBERT and MatBERT for the NER task. For that, they used data from three different NER datasets, each one related with different materials synthesis.</p>
<p>The results, showed that the more specialized BERT models were able to better recognize the different entities. However, it is important to remark that the BERT models were fine-tuned for the task.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="dagdelen_data_extraction_2024_images/trewartha_results.jpg" class="img-fluid figure-img"></p>
<figcaption>Figure taken from Trewartha et al. <span class="citation" data-cites="Trewartha2022">(<a href="#ref-Trewartha2022" role="doc-biblioref">Trewartha et al. 2022</a>)</span> summarizing the results that they obtained with each model.</figcaption>
</figure>
</div>
</section>
</section>
<section id="problem-setting" class="level2">
<h2 class="anchored" data-anchor-id="problem-setting">Problem setting</h2>
<ul>
<li>Almost all the scientific knowledge is contained in scientific texts in an unstructured way.</li>
<li>The classical approaches include a lot of different techniques, each of them has to be trained independently.</li>
<li>For those classical techniques, a lot manually labeled data is needed for each task and technique.</li>
<li>LLMs appear to simplify a lot all the previous options by allowing to perform all the different NLP tasks with one unique model.</li>
</ul>
</section>
<section id="approach" class="level2">
<h2 class="anchored" data-anchor-id="approach">Approach</h2>
<p>They proposed to fine-tune two models, one open-source Llama-2 70B model and a close-source one such as GPT-3, for the NER and RE tasks applied to solid-state materials. As output, they compared two different options: JSON and plain text. They proposed this for three different specificities of data: Doping, MOF and general materials data.</p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Task</th>
<th style="text-align: center;">Training samples</th>
<th style="text-align: center;">Completion format</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Doping</td>
<td style="text-align: center;">413 sentences</td>
<td style="text-align: center;">JSON</td>
</tr>
<tr class="even">
<td style="text-align: center;">Doping</td>
<td style="text-align: center;">413 sentences</td>
<td style="text-align: center;">English sentences</td>
</tr>
<tr class="odd">
<td style="text-align: center;">MOFs</td>
<td style="text-align: center;">507 abstracts</td>
<td style="text-align: center;">JSON</td>
</tr>
<tr class="even">
<td style="text-align: center;">General materials</td>
<td style="text-align: center;">634 abstracts</td>
<td style="text-align: center;">JSON</td>
</tr>
</tbody>
</table>
</section>
<section id="results" class="level2 page-columns page-full">
<h2 class="anchored" data-anchor-id="results">Results</h2>
<p>The results showed first of all that both models performed similar for the tasks. For the exact match, GPT-3 performed slightly better than the Llama-2 model, with overall results for both models around 50% considering all the tasks.</p>
<table class="table">
<thead>
<tr class="header">
<th style="text-align: center;">Task</th>
<th style="text-align: center;">Relation</th>
<th style="text-align: center;">E.M. F1 GPT-3</th>
<th style="text-align: center;">E.M. Llama-3</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">Doping</td>
<td style="text-align: center;">host-dopant</td>
<td style="text-align: center;">0.726</td>
<td style="text-align: center;"><strong>0.821</strong></td>
</tr>
<tr class="even">
<td style="text-align: center;">General</td>
<td style="text-align: center;">formula-name</td>
<td style="text-align: center;"><strong>0.456</strong></td>
<td style="text-align: center;">0.367</td>
</tr>
<tr class="odd">
<td style="text-align: center;">General</td>
<td style="text-align: center;">formula-acronym</td>
<td style="text-align: center;"><strong>0.333</strong></td>
<td style="text-align: center;">0.286</td>
</tr>
<tr class="even">
<td style="text-align: center;">General</td>
<td style="text-align: center;">formula-structure/phase</td>
<td style="text-align: center;"><strong>0.482</strong></td>
<td style="text-align: center;">0.470</td>
</tr>
<tr class="odd">
<td style="text-align: center;">General</td>
<td style="text-align: center;">formula-application</td>
<td style="text-align: center;"><strong>0.537</strong></td>
<td style="text-align: center;">0.516</td>
</tr>
<tr class="even">
<td style="text-align: center;">General</td>
<td style="text-align: center;">formula-description</td>
<td style="text-align: center;"><strong>0.354</strong></td>
<td style="text-align: center;">0.340</td>
</tr>
<tr class="odd">
<td style="text-align: center;">MOFs</td>
<td style="text-align: center;">name-formula</td>
<td style="text-align: center;"><strong>0.483</strong></td>
<td style="text-align: center;">0.276</td>
</tr>
<tr class="even">
<td style="text-align: center;">MOFs</td>
<td style="text-align: center;">name-guest specie</td>
<td style="text-align: center;"><strong>0.616</strong></td>
<td style="text-align: center;">0.408</td>
</tr>
<tr class="odd">
<td style="text-align: center;">MOFs</td>
<td style="text-align: center;">name-application</td>
<td style="text-align: center;"><strong>0.573</strong></td>
<td style="text-align: center;">0.531</td>
</tr>
<tr class="even">
<td style="text-align: center;">MOFs</td>
<td style="text-align: center;">name-description</td>
<td style="text-align: center;"><strong>0.404</strong></td>
<td style="text-align: center;">0.389</td>
</tr>
</tbody>
</table>

<div class="no-row-height column-margin column-container"><div class="">
<ol type="1">
<li>E.M. stands for exact match</li>
</ol>
</div><div class="">
<ol start="2" type="1">
<li>The results presented in this table include for both NER and RE NLP tasks.</li>
</ol>
</div></div>
<p>It is important to comment that the exact match is an approximate lower bound on information extraction performance, since it not consider some cases such as “Lithium ion” named as “Li-ion”, or MOF names such as “ZIF-8” that are described as “mesostructured MOFs formed by Cu2+ and 5hydroxy-1,3-benzenedicarboxylic acid”.</p>
<p>For correctly measure those ambiguities, they did a manual evaluation on a randomly sampled 10% of the test set. These results showed that the score for the extraction was much better than the showed by the exact match. This also showed that some kind of normallization proccess is needed to correctly evaluate this type of extraction tasks.</p>
<p>For the Doping task, three different output schema were consider, <em>DopingEnglish</em>, <em>DopingJSON</em> and <em>DopingExtra-English</em>. They compared the results for the three schema GPT-3 and Llama-2 fine-tuned models with other older models such as MatBERT and Seq2rel.</p>

<div class="no-row-height column-margin column-container"><div class="">
<p>The difference between <em>DopingEnglish</em> and <em>DopingExtra-English</em> is that the last one include some additional information and not only the host-entity relation.</p>
</div></div><p>The results showed that the Llama-2 model return the best results for this task, which are slightly better than the GPT-3 ones. Both LLMs improved by far the other two models.</p>
<table class="table">
<colgroup>
<col style="width: 11%">
<col style="width: 13%">
<col style="width: 32%">
<col style="width: 25%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Model</th>
<th style="text-align: center;">Schema</th>
<th style="text-align: center;">E.M. Precision</th>
<th style="text-align: center;">E.M. Recall</th>
<th style="text-align: center;">E.M. F1</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">MatBERT</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.377</td>
<td style="text-align: center;">0.403</td>
<td style="text-align: center;">0.390</td>
</tr>
<tr class="even">
<td style="text-align: center;">Seq2rel</td>
<td style="text-align: center;">n/a</td>
<td style="text-align: center;">0.420</td>
<td style="text-align: center;">0.605</td>
<td style="text-align: center;">0.496</td>
</tr>
<tr class="odd">
<td style="text-align: center;">GPT-3</td>
<td style="text-align: center;">Doping-JSON</td>
<td style="text-align: center;">0.772</td>
<td style="text-align: center;">0.684</td>
<td style="text-align: center;">0.725</td>
</tr>
<tr class="even">
<td style="text-align: center;">GPT-3</td>
<td style="text-align: center;">Doping-English</td>
<td style="text-align: center;">0.803</td>
<td style="text-align: center;">0.754</td>
<td style="text-align: center;">0.778</td>
</tr>
<tr class="odd">
<td style="text-align: center;">GPT-3</td>
<td style="text-align: center;">DopingExtra-English</td>
<td style="text-align: center;">0.820</td>
<td style="text-align: center;">0.798</td>
<td style="text-align: center;">0.809</td>
</tr>
<tr class="even">
<td style="text-align: center;">Llama-2</td>
<td style="text-align: center;">Doping-JSON</td>
<td style="text-align: center;"><strong>0.836</strong></td>
<td style="text-align: center;">0.807</td>
<td style="text-align: center;"><strong>0.821</strong></td>
</tr>
<tr class="odd">
<td style="text-align: center;">Llama-2</td>
<td style="text-align: center;">Doping-English</td>
<td style="text-align: center;">0.787</td>
<td style="text-align: center;"><strong>0.842</strong></td>
<td style="text-align: center;">0.814</td>
</tr>
<tr class="even">
<td style="text-align: center;">Llama-2</td>
<td style="text-align: center;">DopingExtra-English</td>
<td style="text-align: center;">0.694</td>
<td style="text-align: center;">0.815</td>
<td style="text-align: center;">0.750</td>
</tr>
</tbody>
</table>
<p>A limitation of the method could be that for each of the three extractions tasks, they have to annotate between 100 and 500 text passages. This can be a tedious work. However, to overcome this limitation, they proposed to include human-in-the-loop annotation.</p>
<section id="human-in-the-loop" class="level3">
<h3 class="anchored" data-anchor-id="human-in-the-loop">Human-in-the-loop</h3>
<p>To overcome the limitation of having to manually annotate all the data needed for the fine-tuning process, they sucesfully implemented human-in-the-loop annotation. For that, they fine-tune the model with a small amount of manually labelled data. Then the model is asked to extract data from the other text passages. The returned data by the model is corrected by an human annotator and is feed into the model to further fine-tune it.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="dagdelen_data_extraction_2024_images/ceder_annotation_schema.png" class="img-fluid figure-img"></p>
<figcaption>Figure showing the process used to implement human-in-the-loop annotation.</figcaption>
</figure>
</div>
<p>By using this technique, they greatly reduce the amount of time needed to annotate the last pieces of text compared with the first ones.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="dagdelen_data_extraction_2024_images/ceder_annotation.png" class="img-fluid figure-img"></p>
<figcaption>Figure showing the time reduction across the process of annotation using the human-in-the-loop technique.</figcaption>
</figure>
</div>
<p>By using this annotation method they greatly improve the annotation time solving one of the main drawbacks of fine-tuning an LLM. This great limitation can be seen in another works such as the one by Guo el al. <span class="citation" data-cites="Guo2021">(<a href="#ref-Guo2021" role="doc-biblioref">Guo et al. 2021</a>)</span> in which they employed 13 graduate and postdoc students to annotate about chemical reactions. After that, they have to even check all the annotation. They estimate that this process took them almost 300 hours.</p>
</section>
</section>
<section id="take-aways" class="level2">
<h2 class="anchored" data-anchor-id="take-aways">Take aways</h2>
<ul>
<li>Open source models with proper tuning can yield high-quality results similar to those of closed source models.</li>
<li>Despite some labeled data is needed, the process is simplified a lot with the use of LLMs.</li>
<li>With the fasst and continuous development of the current models, maybe fine-tuning for a simpler task such as data extraction is no furhter needed.</li>
</ul>
</section>
<section id="references" class="level2">
<h2 class="anchored" data-anchor-id="references">References</h2>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-dagdelen_structured_2024" class="csl-entry" role="listitem">
Dagdelen, John, Alexander Dunn, Sanghoon Lee, Nicholas Walker, Andrew S. Rosen, Gerbrand Ceder, Kristin A. Persson, and Anubhav Jain. 2024. <span>“Structured Information Extraction from Scientific Text with Large Language Models.”</span> <em>Nature Communications</em> 15 (1): 1418. <a href="https://doi.org/10.1038/s41467-024-45563-x">https://doi.org/10.1038/s41467-024-45563-x</a>.
</div>
<div id="ref-Guo2021" class="csl-entry" role="listitem">
Guo, Jiang, A. Santiago Ibanez-Lopez, Hanyu Gao, Victor Quach, Connor W. Coley, Klavs F. Jensen, and Regina Barzilay. 2021. <span>“Automated Chemical Reaction Extraction from Scientific Literature.”</span> <em>Journal of Chemical Information and Modeling</em> 62 (9): 2035–45. <a href="https://doi.org/10.1021/acs.jcim.1c00284">https://doi.org/10.1021/acs.jcim.1c00284</a>.
</div>
<div id="ref-Huo2019" class="csl-entry" role="listitem">
Huo, Haoyan, Ziqin Rong, Olga Kononova, Wenhao Sun, Tiago Botari, Tanjin He, Vahe Tshitoyan, and Gerbrand Ceder. 2019. <span>“Semi-Supervised Machine-Learning Classification of Materials Synthesis Procedures.”</span> <em>Npj Computational Materials</em> 5 (1). <a href="https://doi.org/10.1038/s41524-019-0204-1">https://doi.org/10.1038/s41524-019-0204-1</a>.
</div>
<div id="ref-Kim2017" class="csl-entry" role="listitem">
Kim, Edward, Kevin Huang, Adam Saunders, Andrew McCallum, Gerbrand Ceder, and Elsa Olivetti. 2017. <span>“Materials Synthesis Insights from Scientific Literature via Text Extraction and Machine Learning.”</span> <em>Chemistry of Materials</em> 29 (21): 9436–44. <a href="https://doi.org/10.1021/acs.chemmater.7b03500">https://doi.org/10.1021/acs.chemmater.7b03500</a>.
</div>
<div id="ref-Kim2020" class="csl-entry" role="listitem">
Kim, Edward, Zach Jensen, Alexander van Grootel, Kevin Huang, Matthew Staib, Sheshera Mysore, Haw-Shiuan Chang, et al. 2020. <span>“Inorganic Materials Synthesis Planning with Literature-Trained Neural Networks.”</span> <em>Journal of Chemical Information and Modeling</em> 60 (3): 1194–1201. <a href="https://doi.org/10.1021/acs.jcim.9b00995">https://doi.org/10.1021/acs.jcim.9b00995</a>.
</div>
<div id="ref-Kononova2019" class="csl-entry" role="listitem">
Kononova, Olga, Haoyan Huo, Tanjin He, Ziqin Rong, Tiago Botari, Wenhao Sun, Vahe Tshitoyan, and Gerbrand Ceder. 2019. <span>“Text-Mined Dataset of Inorganic Materials Synthesis Recipes.”</span> <em>Scientific Data</em> 6 (1). <a href="https://doi.org/10.1038/s41597-019-0224-1">https://doi.org/10.1038/s41597-019-0224-1</a>.
</div>
<div id="ref-Mavrai2021" class="csl-entry" role="listitem">
Mavračić, Juraj, Callum J. Court, Taketomo Isazawa, Stephen R. Elliott, and Jacqueline M. Cole. 2021. <span>“ChemDataExtractor 2.0: Autopopulated Ontologies for Materials Science.”</span> <em>Journal of Chemical Information and Modeling</em> 61 (9): 4280–89. <a href="https://doi.org/10.1021/acs.jcim.1c00446">https://doi.org/10.1021/acs.jcim.1c00446</a>.
</div>
<div id="ref-mysore2019materials" class="csl-entry" role="listitem">
Mysore, Sheshera, Zach Jensen, Edward Kim, Kevin Huang, Haw-Shiuan Chang, Emma Strubell, Jeffrey Flanigan, Andrew McCallum, and Elsa Olivetti. 2019. <span>“The Materials Science Procedural Text Corpus: Annotating Materials Synthesis Procedures with Shallow Semantic Structures.”</span> <a href="https://arxiv.org/abs/1905.06939">https://arxiv.org/abs/1905.06939</a>.
</div>
<div id="ref-Swain2016" class="csl-entry" role="listitem">
Swain, Matthew C., and Jacqueline M. Cole. 2016. <span>“ChemDataExtractor: A Toolkit for Automated Extraction of Chemical Information from the Scientific Literature.”</span> <em>Journal of Chemical Information and Modeling</em> 56 (10): 1894–904. <a href="https://doi.org/10.1021/acs.jcim.6b00207">https://doi.org/10.1021/acs.jcim.6b00207</a>.
</div>
<div id="ref-Trewartha2022" class="csl-entry" role="listitem">
Trewartha, Amalie, Nicholas Walker, Haoyan Huo, Sanghoon Lee, Kevin Cruse, John Dagdelen, Alexander Dunn, Kristin A. Persson, Gerbrand Ceder, and Anubhav Jain. 2022. <span>“Quantifying the Advantage of Domain-Specific Pre-Training on Named Entity Recognition Tasks in Materials Science.”</span> <em>Patterns</em> 3 (4): 100488. <a href="https://doi.org/10.1016/j.patter.2022.100488">https://doi.org/10.1016/j.patter.2022.100488</a>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="../papers/chem_yield_prediction_2024.html" class="pagination-link" aria-label="Uncertainty-Aware Yield Prediction with Multimodal Molecular Features">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-title">Uncertainty-Aware Yield Prediction with Multimodal Molecular Features</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="../papers/MolCLR_2024.html" class="pagination-link" aria-label="Molecular contrastive learning of representations (MolCLR) via graph neural networks">
        <span class="nav-page-text"><span class="chapter-title">Molecular contrastive learning of representations (MolCLR) via graph neural networks</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>